{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenCV_Video.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TErVcjEXkX7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "def output_keypoints(frame, net, threshold, BODY_PARTS, now_frame, total_frame):\n",
        "    global points\n",
        "    \n",
        "    # 입력 이미지의 사이즈 정의\n",
        "    image_height = 368\n",
        "    image_width = 368\n",
        "\n",
        "    # 네트워크에 넣기 위한 전처리\n",
        "    input_blob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (image_width, image_height), (0, 0, 0), swapRB=False,\n",
        "                                       crop=False)\n",
        "\n",
        "    # 전처리된 blob 네트워크에 입력\n",
        "    net.setInput(input_blob)\n",
        "\n",
        "    # 결과 받아오기\n",
        "    out = net.forward()\n",
        "    # The output is a 4D matrix :\n",
        "    # The first dimension being the image ID ( in case you pass more than one image to the network ).\n",
        "    # The second dimension indicates the index of a keypoint.\n",
        "    # The model produces Confidence Maps and Part Affinity maps which are all concatenated.\n",
        "    # For COCO model it consists of 57 parts – 18 keypoint confidence Maps + 1 background + 19*2 Part Affinity Maps. Similarly, for MPI, it produces 44 points.\n",
        "    # We will be using only the first few points which correspond to Keypoints.\n",
        "    # The third dimension is the height of the output map.\n",
        "    out_height = out.shape[2]\n",
        "    # The fourth dimension is the width of the output map.\n",
        "    out_width = out.shape[3]\n",
        "\n",
        "    # 원본 이미지의 높이, 너비를 받아오기\n",
        "    frame_height, frame_width = frame.shape[:2]\n",
        "\n",
        "    # 포인트 리스트 초기화\n",
        "    points = []\n",
        "\n",
        "    print(f\"============================== frame: {now_frame:.0f} / {total_frame:.0f} ==============================\")\n",
        "    for i in range(len(BODY_PARTS)):\n",
        "\n",
        "        # 신체 부위의 confidence map\n",
        "        prob_map = out[0, i, :, :]\n",
        "\n",
        "        # 최소값, 최대값, 최소값 위치, 최대값 위치\n",
        "        min_val, prob, min_loc, point = cv2.minMaxLoc(prob_map)\n",
        "\n",
        "        # 원본 이미지에 맞게 포인트 위치 조정\n",
        "        x = (frame_width * point[0]) / out_width\n",
        "        x = int(x)\n",
        "        y = (frame_height * point[1]) / out_height\n",
        "        y = int(y)\n",
        "\n",
        "        if prob > threshold:  # [pointed]\n",
        "            cv2.circle(frame, (x, y), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
        "            cv2.putText(frame, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
        "\n",
        "            points.append((x, y))\n",
        "            # print(f\"[pointed] {BODY_PARTS[i]} ({i}) => prob: {prob:.5f} / x: {x} / y: {y}\")\n",
        "\n",
        "        else:  # [not pointed]\n",
        "            cv2.circle(frame, (x, y), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
        "            cv2.putText(frame, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 1, lineType=cv2.LINE_AA)\n",
        "\n",
        "            points.append(None)\n",
        "            # print(f\"[not pointed] {BODY_PARTS[i]} ({i}) => prob: {prob:.5f} / x: {x} / y: {y}\")\n",
        "\n",
        "    return frame\n",
        "\n",
        "\n",
        "BODY_PARTS_MPI = {0: \"Head\", 1: \"Neck\", 2: \"RShoulder\", 3: \"RElbow\", 4: \"RWrist\",\n",
        "                  5: \"LShoulder\", 6: \"LElbow\", 7: \"LWrist\", 8: \"RHip\", 9: \"RKnee\",\n",
        "                  10: \"RAnkle\", 11: \"LHip\", 12: \"LKnee\", 13: \"LAnkle\", 14: \"Chest\",\n",
        "                  15: \"Background\"}\n",
        "\n",
        "POSE_PAIRS_MPI = [[0, 1], [1, 2], [1, 5], [1, 14], [2, 3], [3, 4], [5, 6],\n",
        "                  [6, 7], [8, 9], [9, 10], [11, 12], [12, 13], [14, 8], [14, 11]]\n",
        "\n",
        "BODY_PARTS_COCO = {0: \"Nose\", 1: \"Neck\", 2: \"RShoulder\", 3: \"RElbow\", 4: \"RWrist\",\n",
        "                   5: \"LShoulder\", 6: \"LElbow\", 7: \"LWrist\", 8: \"RHip\", 9: \"RKnee\",\n",
        "                   10: \"RAnkle\", 11: \"LHip\", 12: \"LKnee\", 13: \"LAnkle\", 14: \"REye\",\n",
        "                   15: \"LEye\", 16: \"REar\", 17: \"LEar\", 18: \"Background\"}\n",
        "\n",
        "POSE_PAIRS_COCO = [[0, 1], [0, 14], [0, 15], [1, 2], [1, 5], [1, 8], [1, 11], [2, 3], [3, 4],\n",
        "                   [5, 6], [6, 7], [8, 9], [9, 10], [12, 13], [11, 12], [14, 16], [15, 17]]\n",
        "\n",
        "# 신경 네트워크의 구조를 지정하는 prototxt 파일 (다양한 계층이 배열되는 방법 등)\n",
        "protoFile_mpi = \"/content/gdrive/My Drive/mpi/pose_deploy_linevec.prototxt\"\n",
        "protoFile_coco = \"C:\\\\openpose\\\\models\\\\pose\\\\coco\\\\pose_deploy_linevec.prototxt\"\n",
        "\n",
        "# 훈련된 모델의 weight 를 저장하는 caffemodel 파일\n",
        "weightsFile_mpi = \"/content/gdrive/My Drive/mpi/pose_iter_160000.caffemodel\"\n",
        "weightsFile_coco = \"C:\\\\openpose\\\\models\\\\pose\\\\coco\\\\pose_iter_440000.caffemodel\"\n",
        "\n",
        "# 비디오 경로 (출처: https://pixabay.com/videos/id-21827/)\n",
        "video_path_boy = \"/content/gdrive/My Drive/boy.mp4\"\n",
        "\n",
        "# 비디오 읽어오기\n",
        "capture = cv2.VideoCapture(video_path_boy)\n",
        "\n",
        "# 네트워크 불러오기\n",
        "net_mpi = cv2.dnn.readNetFromCaffe(protoFile_mpi, weightsFile_mpi)\n",
        "\n",
        "# 키포인트를 저장할 빈 리스트\n",
        "points = []\n",
        "\n",
        "while True:\n",
        "    now_frame_boy = capture.get(cv2.CAP_PROP_POS_FRAMES)\n",
        "    total_frame_boy = capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    if now_frame_boy == total_frame_boy:\n",
        "        break\n",
        "    ret, frame_boy = capture.read()\n",
        "    # frame_boy = output_keypoints(frame=frame_boy, net=net_mpi, threshold=0.2, BODY_PARTS=BODY_PARTS_MPI,\n",
        "    #                              now_frame=now_frame_boy, total_frame=total_frame_boy)\n",
        "    cv2_imshow(frame_boy)\n",
        "    if cv2.waitKey(5) == 27:  # esc 입력시 종료\n",
        "        break\n",
        "\n",
        "capture.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}